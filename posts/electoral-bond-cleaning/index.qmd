---
title: "Electoral Bond data: Making it usable"
author: "Praachi Misra"

date: "11/01/2026"
# date-modified: "5/23/2021"

draft: true 

categories: [electoral bond]
image: "image.jpg"

bibliography: /Users/misra.praachi/QuartoBundle/MyLibrary.bib
citation: true
csl: /Users/misra.praachi/QuartoBundle/apa.csl

# freeze computational output
freeze: true
---

<!-- Intro -->

We will create the following folders/ directories to manage the files

1.  data

2.  data/raw (i.e. a folder titled 'raw' within the 'data' folder)

3.  data/processed (i.e. a folder titled 'raw' within the 'data' folder)

4.  fig

<!-- insert image of folder -->

To make code sharing easier and not have to check for directory, we will make the directory we are working in the working directory.

```{r}
#| label: Dir setup
library("here")
here()
```

### Step 1: Obtain files from election Commission of India (ECI)

Go to the [ECI](https://www.eci.gov.in/disclosure-of-electoral-bonds) website and download these files into your "data/*raw*" folder:

1.  *"Details of Electoral Bonds submitted by SBI on 21st March 2024 (EB_Redemption_Details)"* ‚û°Ô∏è \[**rename this file '*party.pdf'***\]

    ![Data on redemption of bonds by political parties](image/party.png){width="1800"}

2.  *"Details of Electoral Bonds submitted by SBI on 21st March 2024 (EB_Purchase_Details)"* ‚û°Ô∏è \[**rename this file '*buyer.pdf'***\]

    ![Data on purchase of bonds by political parties](image/buyer.png){width="1800"}

### Step 2: Convert files from pdf to data frame

We will use Tabula to convert the pdf to a table and data frame for further processing

-   Install [Tabula](https://tabula.technology/)

-   Open the zip folder installed

-   Open the Tabula application. It will open in a browser window

-   Browse ‚ûú select file ‚ûú import

    ![Tabula screen](image/tabula.png){width="1800"}

-   Select the table on page and then select from the drop down: 'Repeat this Selection/ Repeat to all Pages' ‚ûú 'Preview and Export the Extracted data'

    ![](image/tabula_selection.png){width="1800"}

Export to 'data/raw' folder as csv. The files will be labelled **tabula_buyer.csv** & **tabula_party.csv**

### Step 3: Setting up packages for the cleaning

We will be using the following packages: dplyr, lubridate, stringr, tidyr, ggplot2

```{r}
#| label: package mgmt
#| warning: true
#| include: false
#| results: hide


pakg <- c("dplyr", "lubridate", "stringr", "tidyr", "ggplot2")

sapply(pakg, library, character.only = TRUE)

rm(pakg)

```

### Step 4: Starting the cleaning process

1.  Converting csv to data frame

    The csv will be saved and minimally processed. They will be saved in the 'data/processed' folder with the names **df_buyer, df_party**

    ```{r}
    #| label: csv to df 

    df_buyer <- read.csv("./data/raw/tabula_buyer.csv")
    df_party <- read.csv("./data/raw/tabula_party.csv")


    ```

2.  Saving as a data frame in the processed folder

    ```{r}
    save(df_buyer,file = "./data/processed/df_buyer.Rda")
    save(df_party,file = "./data/processed/df_party.Rda")
    ```

    üë∑ When you come back to work after a break, use the *load* function to start working on the data frame again.

    > pakg \<- c("dplyr", "lubridate", "stringr", "tidyr", "ggplot2", "here")
    >
    > sapply(pakg, library, character.only = TRUE)
    >
    > rm(pakg)
    >
    > here()
    >
    > \# get file path & use load function
    >
    > load("./\<path\>/data/processed/df_buyer.Rda")
    >
    > load( "./\<path\>/data/processed/df_party.Rda")

    The data frame can be saved using the save function

    > save(df_buyer, file = "./data/processed/df_buyer.Rda")
    >
    > save(df_party, file = "./data/processed/df_party.Rda")

3.  Checking data type

    Given below are 4 different ways of getting a flavor of the data type (*glimpse, head, str, class*).

    ```{r}

    glimpse(df_buyer)

    ```

    ```{r}
    head(df_buyer, 5)
    ```

    ```{r}

    str(df_party)

    ```

    ```{r}
    lapply(df_party, class)
    ```

4.  As the data is all in character type we will have to change each col to the type we require

    You will some warning messages (NA's introduced by coercion), we will come back to them later

    ```{r}
    # Integer values

    df_buyer <-   df_buyer |> 
        mutate(across(c(Sr.No., Bond.Number, Issue.Teller), as.integer))

    # Date

    df_buyer <-   df_buyer |> 
        mutate(Journal.Date = as.Date(Journal.Date, format = "%d/%b/%Y"), 
              Date.of.Purchase = as.Date(Date.of.Purchase, format = "%d/%b/%Y"),
              Date.of.Expiry = as.Date(Date.of.Expiry, format = "%d/%b/%Y"))

    # Money
    # The presence of commas is throwing off the conversion directly from char to numeric
    # Therefore, we remove the commas using gsub, and then convert the values

    df_buyer <- df_buyer |> 
        mutate(Denominations = as.integer(gsub(",","", Denominations)))

    ```

5.  Repeating the same for the df_party data frame

    ```{r}
    # Integer value
    df_party <- df_party |> 
        mutate(Sr.No.=  as.numeric(Sr.No., Bond.Number, Pay.Teller))

    # Date
    df_party <-  df_party |> 
        mutate(Date.of.Encashment = as.Date(Date.of.Encashment, format = "%d/%b/%Y"))

    # Money 

    df_party <- df_party |> 
        mutate(Denominations = as.integer(gsub(",","",Denominations)))

    ```

6.  Making unique

    Duplicates are removed, by looking for duplicates along all variables. There is a unique serial number for each row, so no useful data should be removed by using the unique function.

    ```{r}

    df_buyer <-  unique(df_buyer)
    df_party <- unique(df_party)

    # Count duplicated rows

    sum(duplicated(df_buyer))
    sum(duplicated(df_party))
    ```

7.  Checking for data completeness in the csv files

    -- The buyer.pdf has 18871 rows

    -- The party.pdf has 20421 rows

    ```{r}

    print(paste(sum(is.na(df_party)),": NA in df_party"))
    print(paste(sum(is.na(df_buyer)),"NA in :df_buyer"))


    ```

See the rows that contain NA values

```{r}
df_buyer[!complete.cases(df_buyer), ]
```

Seeing for df_party as well

```{r}

df_party[!complete.cases(df_party), ]
```

9.  Remove header row from data

```{r}

df_buyer <- df_buyer |> 
    filter(!grepl("Reference", Reference.No...URN.))

df_buyer[!complete.cases(df_buyer), ]
```

For df_party

```{r}

df_party <- df_party |> 
    filter(!grepl("Name", Name.of.the.Political.Party))

df_party[!complete.cases(df_party), ]
```

9.  Identify the missing rows using Sr. No.

    We now have to find the missing rows. We can use the absence of a serial number (between 1:18871 for df_buyer and 1:20421 for df_party)

    ```{r}

    ```

10. Cleaning variable/column names

    . followed by small case to be removed

    ```         
    names(frame) <- sub("\.$", "", names(frame))
    ```

11. Consolidating based on Names and Dates

### Step 5: Cleaning Names
